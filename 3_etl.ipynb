{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run package_import.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "sqlEngine = create_engine('mysql+pymysql://root:@127.0.0.1/nlp_with_disaster_tweets', pool_recycle=3600)\n",
    "dbConnection = sqlEngine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine train and test data for the following data cleansing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_sql_query(\n",
    "\n",
    "'''\n",
    "select *\n",
    "    ,'train' as source_file\n",
    "from raw_train\n",
    "union all\n",
    "select *\n",
    "    ,Null as target\n",
    "    ,'test' as source_file\n",
    "from raw_test\n",
    "\n",
    "'''\n",
    ",dbConnection)\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text: str) -> str:\n",
    "    '''\n",
    "    input:\n",
    "    text: text where urls are to be removed\n",
    "\n",
    "    output:\n",
    "    return text excluding urls\n",
    "    '''\n",
    "\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    return url.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['text_transformed'] = df_combined['text'].apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text:str) -> str:\n",
    "    '''\n",
    "    input:\n",
    "    text: text where html tags are to be removed\n",
    "\n",
    "    output:\n",
    "    return text where html tags are removed\n",
    "    '''\n",
    "\n",
    "    html = re.compile(r'<.*?>')\n",
    "\n",
    "    return html.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['text_transformed'] = df_combined['text_transformed'].apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Romoving Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text: str) -> str:\n",
    "    '''\n",
    "    input:\n",
    "    text: text where emojis are to be removed\n",
    "\n",
    "    output:\n",
    "    return text where emojis are removed\n",
    "    '''\n",
    "\n",
    "    emojis = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emojis.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['text_transformed'] = df_combined['text_transformed'].apply(lambda x: remove_emojis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text: str) -> str:\n",
    "    '''\n",
    "    input:\n",
    "    text: text where punctuation are to be removed\n",
    "\n",
    "    output:\n",
    "    return text where punctuation are removed\n",
    "    '''\n",
    "\n",
    "    punc = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    return text.translate(punc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['text_transformed'] = df_combined['text_transformed'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spelling correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spellings(text: str) -> str:\n",
    "    '''\n",
    "    '''\n",
    "    correct_text = []\n",
    "    words = text.split()\n",
    "    miss_spelling = spell.unknown(words)\n",
    "    for word in words:\n",
    "        if word in miss_spelling:\n",
    "            correct_text.append(spell.correction(word))\n",
    "        else:\n",
    "            correct_text.append(word)\n",
    "    \n",
    "    return ' '.join(correct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['text_transformed'] = df_combined['text_transformed'].apply(lambda x: correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_sql('transformed_combination', dbConnection, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1e648b511f995978624ce57c81fec97ef276ceed8c20bc85d5834907df54f6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
